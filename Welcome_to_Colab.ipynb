{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parthgiri01/WEEK-4-TEST/blob/main/Welcome_to_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import lightgbm as lgb\n",
        "import warnings\n",
        "import numpy as np # Import numpy\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- Data Loading (Placeholder) ---\n",
        "# NOTE: Replace this with your actual data loading code for the Bot-IoT dataset.\n",
        "# Example: df = pd.read_csv('your_bot_iot_dataset.csv')\n",
        "# For demonstration, we will create a simple mock dataset with class imbalance.\n",
        "print(\"Loading dataset...\")\n",
        "np.random.seed(42)\n",
        "num_samples = 10000\n",
        "num_features = 20\n",
        "X = pd.DataFrame(np.random.rand(num_samples, num_features))\n",
        "\n",
        "# Create imbalanced labels: 95% benign (0), 5% malicious (1)\n",
        "y = np.zeros(num_samples, dtype=int)\n",
        "num_anomalies = int(num_samples * 0.05)\n",
        "y[:num_anomalies] = 1\n",
        "np.random.shuffle(y)\n",
        "y = pd.Series(y)\n",
        "\n",
        "print(f\"Dataset loaded. Class distribution: {y.value_counts()}\")\n",
        "\n",
        "# --- Pre-processing ---\n",
        "print(\"Pre-processing data...\")\n",
        "# Split data before scaling to prevent data leakage\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Scaling numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Handle class imbalance using SMOTE on the training data\n",
        "print(\"Applying SMOTE to balance the training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train_scaled, y_train)\n",
        "print(f\"Training data class distribution after SMOTE: {pd.Series(y_train_res).value_counts()}\")\n",
        "\n",
        "# --- Model Training ---\n",
        "print(\"Training LightGBM model...\")\n",
        "lgbm_model = lgb.LGBMClassifier(random_state=42)\n",
        "lgbm_model.fit(X_train_res, y_train_res)\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# --- Evaluation ---\n",
        "print(\"Evaluating model performance on the test set...\")\n",
        "y_pred = lgbm_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "# Calculate False Positive Rate (FP / (FP + TN))\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "fp_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "\n",
        "# Print results\n",
        "print(\"\\n--- Model Performance Metrics ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"False Positive Rate: {fp_rate:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCBChaPIw9bP",
        "outputId": "ed082155-364e-41a1-b1c9-cd9c1fc56f58"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Dataset loaded. Class distribution: 0    9500\n",
            "1     500\n",
            "Name: count, dtype: int64\n",
            "Pre-processing data...\n",
            "Applying SMOTE to balance the training data...\n",
            "Training data class distribution after SMOTE: 0    6650\n",
            "1    6650\n",
            "Name: count, dtype: int64\n",
            "Training LightGBM model...\n",
            "[LightGBM] [Info] Number of positive: 6650, number of negative: 6650\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003412 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5100\n",
            "[LightGBM] [Info] Number of data points in the train set: 13300, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "Model training complete.\n",
            "Evaluating model performance on the test set...\n",
            "\n",
            "--- Model Performance Metrics ---\n",
            "Accuracy: 0.8443\n",
            "Precision: 0.9065\n",
            "Recall: 0.8443\n",
            "F1-Score: 0.8733\n",
            "False Positive Rate: 0.1186\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}